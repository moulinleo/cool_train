{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filter out warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = '../dataset/'\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(main_folder_path) if f.is_dir() and \"20231207\" in f.name and \"tbl_AR41\" in f.name]\n",
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_new_dataset = [107, 131, 136, 172, 181, 194]\n",
    "\n",
    "date_string = '20231207'\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(main_folder_path) if f.is_dir() and date_string in f.name and \"tbl_AR41\" in f.name]\n",
    "\n",
    "# Create a 3x2 grid of histograms\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown']\n",
    "\n",
    "\n",
    "for jj, subfolder in enumerate(subfolders):\n",
    "    files = [f.path for f in os.scandir(subfolder) if f.is_file()]\n",
    "    file_path = files[0]\n",
    "    raw_data = pd.read_csv(file_path, sep=';')\n",
    "    raw_timestamps = raw_data['timestamps_UTC']\n",
    "    intervals = pd.to_datetime(raw_timestamps).diff()\n",
    "    \n",
    "    intervals = intervals[intervals.dt.total_seconds() < 150]\n",
    "\n",
    "    # Index axs using jj to get the correct subplot\n",
    "    ax = axs[jj % 2,jj // 2]\n",
    "    \n",
    "    # Set x-axis range\n",
    "    ax.set_xlim(0, 100)  # Adjust the range as needed\n",
    "    \n",
    "    # Set y-axis range\n",
    "    ax.set_ylim(0, 120000)  # Adjust the range as needed\n",
    "\n",
    "    n, bins, patches = ax.hist(intervals.dt.total_seconds(), bins=60, label=f'Train {trains_new_dataset[jj]}', color=colors[jj])\n",
    "    ax.set(xlabel='Time Interval (seconds)', ylabel='Frequency')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Calculate mode(s)\n",
    "    calc_mode = False\n",
    "    if calc_mode:\n",
    "        modes = mode(intervals.dt.total_seconds()).mode\n",
    "\n",
    "        # Display mode(s) as vertical line(s)\n",
    "        for mode_val in modes:\n",
    "            ax.axvline(mode_val, color='red', linestyle='dashed', linewidth=2)\n",
    "\n",
    "        # Annotate if there is more than one mode\n",
    "        if len(modes) > 1:\n",
    "            ax.text(0.5, 0.95, f'Multiple Modes', color='red', transform=ax.transAxes, ha='center', va='center', alpha=0.2)\n",
    "\n",
    "    # Set title instead of legend\n",
    "    ax.set_title(f'Train {trains_new_dataset[jj]}')\n",
    "    ax.grid(alpha=0.2)\n",
    "    # Remove the legend\n",
    "    ax.legend([])\n",
    "    \n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig('../figures/distribution_time_intervals.png') \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regles pour decouper chaque segment avec des donnees continues\n",
    "Le but de cette section est de decouper pouir chaque trains en segments de donnees en fonction de l'interval entre chaque timedelta\n",
    "\n",
    "Plus tard, il serait interessant d'egalement decouper en fonction de la distance parcourue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/tbl_AR41_train136_20231207/tbl_AR41 - Train 136 - 2023-12-07.csv',sep=';')\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamps_UTC'])\n",
    "\n",
    "# Calculate time difference between consecutive points\n",
    "df['time_diff'] = df['timestamp'].diff()\n",
    "\n",
    "# Set a threshold for time difference (you may need to adjust this based on your data)\n",
    "time_threshold = pd.Timedelta('0 days 00:15:00')  # We consider >15min is a different segment\n",
    "\n",
    "# Identify segments where the train is moving or standing still\n",
    "df['movement'] = np.where(df['time_diff'] > time_threshold, 'New Segment', '')\n",
    "\n",
    "# Create a segment ID for each segment\n",
    "df['segment_id'] = (df['movement'] == 'New Segment').cumsum()\n",
    "\n",
    "# Filter segments with at least 10,000 points\n",
    "large_segments = df.groupby('segment_id').filter(lambda x: len(x) >= 1000)\n",
    "\n",
    "# Count the average number of segments per day for each train\n",
    "average_segments_per_day_train1 = large_segments_train1.groupby(large_segments_train1['timestamp'].dt.date).agg({'segment_id': 'nunique'}).mean()\n",
    "\n",
    "# Drop temporary columns\n",
    "df = df.drop(columns=['time_diff', 'movement'])\n",
    "\n",
    "# Print the segmented dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_new_dataset = [107, 131, 136, 172, 181, 194]\n",
    "\n",
    "date_string = '20231207'\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(main_folder_path) if f.is_dir() and date_string in f.name and \"tbl_AR41\" in f.name]\n",
    "\n",
    "list_of_dataframes = []\n",
    "\n",
    "for jj, subfolder in enumerate(subfolders):\n",
    "    files = [f.path for f in os.scandir(subfolder) if f.is_file()]\n",
    "    file_path = files[0]\n",
    "    raw_data = pd.read_csv(file_path, sep=';')\n",
    "    list_of_dataframes.append(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set a threshold for time difference (you may need to adjust this based on your data)\n",
    "time_threshold = pd.Timedelta('0 days 00:15:00')  # Adjust according to your data\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "for i, df_train in enumerate(list_of_dataframes):\n",
    "    # Calculate time difference between consecutive points for each train\n",
    "    df_train['time_diff'] = df_train['timestamp'].diff()\n",
    "\n",
    "    # Identify segments where each train is moving or standing still\n",
    "    df_train['movement'] = np.where(df_train['time_diff'] > time_threshold, 'New Segment', '')\n",
    "\n",
    "    # Create a segment ID for each segment for each train\n",
    "    df_train['segment_id'] = (df_train['movement'] == 'New Segment').cumsum()\n",
    "\n",
    "    # Filter segments with at least 10,000 points for each train\n",
    "    large_segments = df_train.groupby('segment_id').filter(lambda x: len(x) >= 1000)\n",
    "\n",
    "    # Plot the segmented data for each train over time\n",
    "    plt.scatter(large_segments['timestamp'], [i + 1] * len(large_segments), marker='o', label=f'Train {trains_new_dataset[i]}', s=4)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Train ID')\n",
    "plt.title('Train Segments Over Time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set a threshold for time difference (you may need to adjust this based on your data)\n",
    "time_threshold = pd.Timedelta('0 days 00:15:00')  # Adjust according to your data\n",
    "\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown']\n",
    "\n",
    "# Create a 1x6 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=len(list_of_dataframes), ncols=1, figsize=(10, 20), sharey=True)\n",
    "\n",
    "for i, df_train in enumerate(list_of_dataframes):\n",
    "    # Create a column 'date' with the current date based on the 'timestamp'\n",
    "    df_train['date'] = df_train['timestamp'].dt.date\n",
    "\n",
    "    # Count the number of samples per day for each train\n",
    "    samples_per_day = df_train.groupby('date').size().reset_index(name='sample_count')\n",
    "\n",
    "    # Plot the number of samples per day for each train\n",
    "    axes[i].bar(samples_per_day['date'], samples_per_day['sample_count'], label=f'Train {trains_new_dataset[i]}',color=colors[i])\n",
    "    axes[i].set_title(f'Train {trains_new_dataset[i]}')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "# Set a common y-axis label\n",
    "axes[0].set_ylabel('Sample Count')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig('../figures/comparison_samples_per_day.png') \n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
